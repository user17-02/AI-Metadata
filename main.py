import os
import json
import requests
from fastapi import FastAPI, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from dotenv import load_dotenv
from langgraph.graph import StateGraph, START, END
from typing import TypedDict

#  Load environment variables
load_dotenv()

FEATHERLESS_API_KEY = os.getenv("FEATHERLESS_API_KEY")
if not FEATHERLESS_API_KEY:
    raise RuntimeError(" FEATHERLESS_API_KEY not found in .env file")

FEATHERLESS_API_URL = "https://api.featherless.ai/v1/chat/completions"
MODEL_NAME = "Sao10K/Fimbulvetr-11B-v2"

HEADERS = {
    "Authorization": f"Bearer {FEATHERLESS_API_KEY}",
    "Content-Type": "application/json",
}

#  Load KDP categories
KDP_FILE_PATH = os.path.join(os.path.dirname(__file__), "kdp_categories.json")
print(f" Looking for KDP file at: {KDP_FILE_PATH}")
if not os.path.exists(KDP_FILE_PATH):
    raise RuntimeError(f" Missing required file: {KDP_FILE_PATH}")

with open(KDP_FILE_PATH, "r", encoding="utf-8") as f:
    KDP_CATEGORIES = json.load(f)

#  Initialize FastAPI
app = FastAPI(title="AI Metadata Generator (Featherless API + LangGraph Agent)")

#  CORS setup
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)


@app.get("/")
def home():
    return {"message": " Featherless + LangGraph AI Metadata API is running!"}


# Core: Call Featherless API
def call_featherless_api(content: str) -> dict:
    prompt = f"""
    You are an expert Amazon KDP metadata optimizer.

    Analyze the following book idea or content:
    ---
    {content}
    ---

    Generate a **valid JSON** with the following structure:
    {{
      "title": "Main catchy book title (5-8 words)",
      "subtitle": "An engaging subtitle that expands on the title",
      "keywords": ["3-7 relevant SEO-friendly keywords"],
      "categories": ["1-3 appropriate Amazon KDP categories"],
      "description": "A professional, reader-focused description (80-150 words)"
    }}

     Ensure the JSON is strictly valid — no markdown or extra text.
    """

    payload = {
        "model": MODEL_NAME,
        "messages": [
            {"role": "system", "content": "You are an AI metadata optimizer for Amazon KDP."},
            {"role": "user", "content": prompt},
        ],
        "temperature": 0.6,
        "max_tokens": 900,
    }

    response = requests.post(FEATHERLESS_API_URL, headers=HEADERS, json=payload)
    response.raise_for_status()
    data = response.json()
    raw_text = data["choices"][0]["message"]["content"].strip()

    try:
        return json.loads(raw_text)
    except json.JSONDecodeError:
        # Handle cases where AI adds ```json blocks
        cleaned = raw_text.strip().split("```json")[-1].split("```")[0]
        return json.loads(cleaned)


# Optional category validation (non-blocking)
def validate_categories(categories):
    if not categories:
        return []
    invalid = []
    for cat in categories:
        if cat not in KDP_CATEGORIES:
            invalid.append(cat)
    if invalid:
        print(f" Warning: These categories are not in KDP list → {invalid}")
    else:
        print(" All categories validated successfully.")
    return categories


#  LangGraph Agent Setup
class MetadataState(TypedDict):
    content: str
    metadata: dict


def generate_metadata_node(state: MetadataState) -> MetadataState:
    content = state["content"]
    result = call_featherless_api(content)

    # Validate category list
    if "categories" in result:
        result["categories"] = validate_categories(result["categories"])

    # Ensure subtitle always present
    if "subtitle" not in result or not result["subtitle"]:
        result["subtitle"] = "A captivating subtitle generated by AI"

    state["metadata"] = result
    return state


#  Build LangGraph
graph = StateGraph(MetadataState)
graph.add_node("generate_metadata", generate_metadata_node)
graph.add_edge(START, "generate_metadata")
graph.add_edge("generate_metadata", END)
compiled_graph = graph.compile()


#  Endpoint: Run the full flow
@app.post("/run-flow")
async def run_flow(request: dict):
    try:
        input_text = request.get("input", "").strip()
        if not input_text:
            raise HTTPException(status_code=400, detail="Missing 'input' text.")
        print(f" Received input: {input_text}")

        state_input = {"content": input_text}
        final_state = compiled_graph.invoke(state_input)
        metadata = final_state["metadata"]

        return {"result": {"status": "done", "metadata": metadata}}

    except Exception as e:
        print(" API Error:", e)
        raise HTTPException(status_code=500, detail=str(e))


#  Run manually
if __name__ == "__main__":
    import uvicorn
    uvicorn.run("main:app", host="127.0.0.1", port=8000, reload=True)
